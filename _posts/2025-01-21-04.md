---
layout: single
title:  "AI 3.AI 알고리즘의 작동 방식"
categories: IT기초
tags: AI
---



## 서론

인공지능(AI)은 현대 사회의 다양한 분야에서 혁신을 주도하고 있으며, 그 핵심에는 **특정 목적을 위해 설계된 컴퓨터 알고리즘**이 존재합니다. AI 알고리즘은 **주어진 입력에 기반하여 자동으로 과업을 처리**하며, 이는 개발자가 직접 알고리즘을 입력하는 기존 방식과는 대조적입니다. **데이터를 기반으로 컴퓨터가 스스로 알고리즘을 학습**한다는 점이 AI 알고리즘의 가장 큰 특징입니다. 본 상세 설명문에서는 AI 알고리즘의 작동 방식, 학습 과정, 다양한 모델, 그리고 실제 활용 사례를 하버드 비즈니스 리뷰 스타일로 상세하게 분석하고자 합니다.

## AI 알고리즘의 기본 원리

AI 알고리즘은 '알고리즘을 위한 알고리즘'이라고도 불리며, 학습과 예측이라는 두 가지 주요 단계로 구성됩니다.

### 학습 알고리즘 (Learning Algorithm)

- **학습**은 주어진 데이터를 분석하여 특정 작업을 수행할 수 있는 **규칙이나 패턴을 발견하는 과정**입니다.
- 학습 알고리즘의 역할은 **데이터로부터 주어진 과업을 수행할 알고리즘을 찾아내는 것**입니다.
- 예를 들어, 숫자 데이터를 내림차순으로 정렬하는 경우, 컴퓨터는 **학습 데이터와 학습 알고리즘을 통해 수학적 지식 없이 정렬 알고리즘을 스스로 생성**합니다.
- 과거에는 언어 번역 알고리즘을 만들기 위해 컴퓨터 전문가와 언어학자들이 규칙을 개발했지만, AI 학습 알고리즘은 **수십만 개의 문서에서 스스로 문법을 찾아내어** 자동 언어 번역 성능을 인간 수준으로 끌어올렸습니다.

### 예측 알고리즘 (Prediction Algorithm)

- **예측**은 **학습된 모형을 사용하여 새로운 데이터에 대한 결과를 추론하는 과정**입니다.
- 예측 알고리즘은 **학습 알고리즘을 통해 학습**되며, 특정 과업을 수행하는 역할을 합니다.
- 정렬 알고리즘의 예시에서, 개발자가 만든 알고리즘에 숫자 데이터를 입력하면, 큰 숫자부터 작은 숫자 순으로 정렬된 새로운 데이터가 출력됩니다. 이것이 예측 단계에 해당하며, **개발자가 구현한 것은 예측 알고리즘**으로 볼 수 있습니다.

## AI 작동 과정의 이해

AI 알고리즘은 문제를 정의하고, 데이터를 수집하며, 학습하고, 예측하며, 최종적으로 성능을 평가하고 모니터링하는 과정을 거칩니다.

### 문제 정의 (Problem Definition)

- AI 프로세스는 **문제를 정확히 정의하는 것**으로 시작합니다.
- **정의가 제대로 되지 않으면 이후 과정이 잘 진행되더라도 원하는 결과를 얻을 수 없습니다**.
- 예를 들어, 주차장 자동화 시스템을 구축하기 위해 번호판 인식 AI를 개발할 때, **‘숫자와 문자의 인식’이 아닌 ‘자동차 번호판의 숫자와 문자의 인식’**으로 문제를 정의해야 합니다.

### 데이터 수집 (Data Collection)

- 정의된 문제에 따라 **컴퓨터가 학습할 수 있는 데이터를 수집**해야 합니다.
- 데이터는 **모집단 전체를 대표할 수 있어야 하며**, 특정 연령층의 데이터만 학습하면 다른 연령층에서는 인식률이 떨어질 수 있습니다.
- 양질의 대규모 데이터를 구축하는 것이 AI 알고리즘 성공의 핵심입니다.

### 학습 알고리즘 (Learning Algorithm)

- 수집한 데이터를 이용하여 학습시키는 과정으로, 목적과 방식에 따라 다양한 알고리즘을 선택할 수 있습니다.
- **분류 모형**은 인물 이미지의 성별 분류처럼 자동으로 판단해야 하는 경우에 사용되고, **생성형 AI 알고리즘**은 새로운 사진이나 문서를 생성하는 경우에 사용됩니다.
- **강화 학습 알고리즘**은 게임이나 바둑처럼 상호작용이 필요한 상황에 사용됩니다.
- 학습 알고리즘은 학습 데이터를 입력으로 받아 예측 알고리즘을 출력으로 제공하며, 예측 알고리즘은 새로운 정보를 입력으로 받아 최적의 의사결정을 출력합니다.

### 학습 모형 선택 (Model Selection)

- 모든 함수 중에서 예측을 가장 잘하는 함수를 찾는 것은 불가능에 가깝기 때문에, **인공지능 모형**을 사용합니다.

- 인공지능 모형은 **입력 변수로부터 출력 변수를 예측하는 함수 중에서 특정 파라미터로 표현되는 함수**를 의미합니다.

- 가장 간단한 모형은 데이터의 특성과 결과 사이에 선형 관계를 보이는 

  선형 모형

  입니다.

  - **선형 회귀 모형**: y=ax+b와 같은 함수를 사용하며, 파라미터 a와 b를 통해 데이터의 선형 관계를 이해합니다.

- 선형 모형의 정확도가 낮기 때문에 **심층 신경망 (딥러닝)**이 많이 사용됩니다.

  - **딥러닝**은 여러 층의 선형 및 비선형 변환을 거쳐 출력을 내는 함수를 통칭합니다.
  - **CNN (합성곱 신경망)**: 이미지 데이터에 특화된 딥러닝 모형으로, 이미지 분류 및 생성에 사용됩니다.
  - **RNN (순환 신경망)**: 문서 데이터에서 단어 간의 순서를 고려하여 모형화한 것으로, 자연어 처리 분야에 사용됩니다.
  - **트랜스포머**: 단어 간의 연관성을 자동으로 탐지하여 각 단어를 벡터로 변환하는 모형으로, 챗GPT와 같은 대형 언어 모델의 기반입니다.

### 파라미터 학습 (Parameter Learning)

- 학습 모형을 선택한 후에는 **예측을 가장 잘하는 파라미터**를 찾아야 하며, 이를 인공지능의 학습이라고 합니다.

- 파라미터는 데이터 학습을 통해 찾을 수 있는 내부 변수로, **모형의 성능에 직접적인 영향**을 미칩니다.

- 목적 함수

  는 모형의 성능을 정량적으로 평가하며, 모형의 학습 방향을 제시합니다.

  - **평균 제곱 오차 (MSE)**: 회귀 문제에서 예측값과 실제값의 차이를 제곱하여 평균을 낸 값입니다.
  - **교차 엔트로피 손실**: 분류 문제에서 예측이 실제 레이블의 분포와 얼마나 잘 일치하는지를 측정하는 데 사용됩니다.

### 예측 성능 측정 및 모니터링 (Performance Measurement and Monitoring)

- AI 학습의 최종 목표는 미래 데이터에서 예측을 잘하는 모형을 찾는 것입니다.

- 주어진 데이터를 임의로 **학습 데이터와 예측 데이터로 나누어** 모형의 성능을 평가합니다.

- 성능이 기준에 미달하는 경우, **문제 정의, 데이터, 알고리즘 선택을 재고**해야 합니다.

- 모형을 실제 업무에 적용한 후에도 

  지속적인 모니터링

  이 필요하며, 새로운 데이터가 추가되면 재학습을 고려해야 합니다.

  - **연속적 학습**: 지속적으로 변하는 환경에서 새로운 데이터를 학습하는 기법입니다.
  - **전이 학습**: 한 작업에서 학습된 지식을 다른 작업에 적용하여 학습 시간을 단축하고 성능을 높이는 기법입니다.
  - **도메인 적응**: 특정 도메인에서 학습된 모형을 다른 도메인에서도 잘 작동하도록 조정하는 기법입니다.

## 머신러닝 (Machine Learning)

### 머신러닝의 정의

- **머신러닝**은 **데이터의 패턴을 스스로 학습하여 예측을 수행하는 알고리즘**입니다.
- 기존의 전통적인 AI는 인간이 규칙과 논리를 프로그래밍해야 했지만, 머신러닝은 **데이터 안에 숨겨진 복잡한 구조나 패턴을 발견**하고 스스로 학습합니다.
- 머신러닝 구현 과정은 데이터 수집, 학습 모델 선택, 목적 함수 정의, 파라미터 학습 단계로 구성됩니다.

### 머신러닝 알고리즘의 종류

머신러닝 알고리즘은 학습하려는 문제 유형에 따라 크게 세 가지로 나뉩니다.

- 지도 학습 (Supervised Learning)
  - 입력 데이터와 함께 **정답(라벨)**을 학습하는 방식입니다.
  - 새로운 데이터에 대한 정답을 예측하는 데 사용됩니다.
    - **분류 (Classification)**: 라벨이 이산적으로 주어지는 경우 (예: 강아지 유무 판단).
    - **회귀 (Regression)**: 라벨이 연속적인 숫자로 주어지는 경우 (예: 집값 예측).
- 비지도 학습 (Unsupervised Learning)
  - **명시적인 라벨 없이 데이터만을 학습**하는 방식입니다.
  - 데이터가 나타내는 확률 분포의 특성을 파악하는 데 사용됩니다.
    - **군집화 (Clustering)**: 비슷한 특성을 가진 데이터를 그룹으로 묶는 방식 (예: 불량 웨이퍼 분류).
    - **차원 축소 (Dimensionality Reduction)**: 고차원 데이터를 저차원으로 축소하는 기술 (예: 주성분 분석).
    - **생성형 AI**: 데이터로부터 확률 분포를 학습하고, 이를 통해 새로운 데이터를 생성하는 기술 (예: 챗GPT).
- 강화 학습 (Reinforcement Learning)
  - 모델이 **주변 환경과 상호작용하며 최대한 많은 보상**을 받도록 학습하는 방식입니다.
  - 순차적인 의사결정이 필요한 문제에 효과적입니다 (예: 로봇 경로 찾기, 자율 주행, 게임 AI).

### 머신러닝 성능 평가

- 머신러닝 모델의 궁극적인 목표는 **실제 환경에서 처음 보는 데이터에도 우수한 성능을 보이는 것**입니다.

- 모델의 성능은 문제 유형에 따라 다양한 지표를 사용하여 평가합니다.

  - 분류 문제

    :

    - **정확도 (Accuracy)**: 전체 예측 중 올바르게 예측한 비율.
    - **정밀도 (Precision)**: 모델이 양성으로 예측한 것 중 실제로 양성인 것의 비율.
    - **재현율 (Recall)**: 실제 양성 중 모델이 양성으로 예측한 비율.
    - **F1 스코어**: 정밀도와 재현율의 조화 평균.

  - 회귀 문제

    :

    - **평균 제곱 오차 (MSE)**: 예측값과 실제값 차이의 제곱 평균.
    - **제곱근 평균 제곱 오차 (RMSE)**: MSE의 제곱근.
    - **평균 절대 오차 (MAE)**: 예측값과 실제값 차이의 절대값 평균.

- 모델 평가는 

  훈련 세트와 테스트 세트

  로 데이터를 나누어 진행합니다.

  - **훈련-테스트 분할법**: 데이터를 훈련 세트와 테스트 세트로 나누어 성능을 평가.
  - **교차 검증**: 데이터를 K개의 세트로 나누어 K번 반복하여 평균 성능을 평가.

- 모델의 성능이 좋지 않을 경우, 

  과소적합 또는 과대적합

  을 의심해 볼 수 있습니다.

  - **과소적합 (Underfitting)**: 모델이 너무 단순하여 데이터의 기본적인 패턴을 학습하지 못하는 경우.
  - **과대적합 (Overfitting)**: 모델이 너무 복잡하여 데이터의 노이즈까지 학습하는 경우.
  - **정규화 (Regularization)**: 모델의 복잡도를 제한하거나 페널티를 부과하여 과대적합을 방지하는 학습 방법.
  - **이중 하강 현상**: 모델 크기가 커질수록 성능이 저하되다가 다시 개선되는 현상.

## 딥러닝 (Deep Learning)

### 딥러닝의 정의

- **딥러닝**은 머신러닝의 한 분야로, **심층 신경망 (DNN)**을 사용하여 복잡한 데이터 특성을 스스로 학습하고 추출합니다.

- 심층 신경망

  은 여러 층으로 이루어져 있으며, 각 층은 이전 층의 출력을 입력으로 받아 특정 변환을 수행한 후 다음 층으로 전달합니다.

  - **뉴런 (Neuron)**: 입력 신호를 받아 처리하고 출력을 생성하는 기본 단위.
  - **학습 가능한 파라미터**: 뉴런 간의 연결 강도를 나타내는 값 (주로 가중치와 편향).
  - **활성화 함수**: 입력 신호의 총합을 비선형적으로 변환하여 뉴런의 최종 출력을 결정하는 함수.

- 딥러닝의 단점은 **많은 파라미터와 데이터가 필요**하고, **하이퍼파라미터**를 찾기 위해 많은 시행착오가 필요하며, **모델의 작동 방식을 파악하기 어렵다**는 점입니다.

### 심층 신경망의 구조

- **입력층**: 외부에서 데이터를 받아 신경망 내부로 전달하는 역할.
- **은닉층**: 데이터의 패턴이나 특징을 학습하는 층.
- **출력층**: 최종 결과나 예측을 나타내는 층.
- 심층 신경망의 대표적인 모델:
  - **완전 연결 신경망**: 모든 뉴런이 서로 연결된 기본 구조.
  - **합성곱 신경망 (CNN)**: 이미지 처리에 최적화.
  - **순환 신경망 (RNN)**: 연속된 데이터 처리에 적합.
  - **잔차 신경망**: 복잡한 이미지 분류 작업에 사용.
  - **트랜스포머**: 자연어 처리 분야에서 사용되며, 거대 언어 모델의 기반.

### 심층 신경망의 학습 과정

- 심층 신경망의 학습 과정은 

  순전파와 역전파

  로 구성됩니다.

  - **순전파**: 입력 데이터를 신경망에 정방향으로 통과시켜 예측값을 얻는 과정.
  - **역전파**: 예측값과 실제값을 비교하여 손실을 계산하고, 파라미터 값을 조정하는 과정.
  - **경사 하강법**: 손실 함수를 최소화하기 위해 기울기를 따라 매개변수를 업데이트하는 최적화 알고리즘.

## 생성형 AI (Generative AI)

### 생성형 AI의 정의

- **생성형 AI**는 기존 데이터의 분포를 학습하여 **새로운 데이터를 생성하는 기술**입니다.
- 판별 AI 모델(Discriminative Model)과 달리, 생성형 AI 모델은 **데이터 자체의 확률 분포**를 학습합니다.
- 생성형 AI 모델은 라벨 없이 데이터 학습이 가능하며, **대규모 데이터를 활용한 학습**이 가능합니다.

### 생성형 AI의 원리

- 생성형 AI는 학습 단계와 샘플링 및 생성 단계를 거칩니다.

  - **학습 단계**: 기존 데이터를 학습하여 데이터의 분포를 파악.
  - **샘플링 및 생성 단계**: 학습된 데이터 분포를 기반으로 새로운 데이터를 생성.

- 잠재 변수 모델

  : 데이터를 생성할 때 잠재 변수를 사용.

  - **GANs (Generative Adversarial Networks)**: 생성기와 판별기가 경쟁적으로 학습하여 새로운 데이터를 생성.
  - **VAEs (Variational Autoencoders)**: 인코더와 디코더로 구성되어 저차원의 잠재 변수를 통해 데이터를 생성.
  - **확산 모델 (Diffusion Model)**: 데이터에 노이즈를 추가하고 다시 복원하는 방식으로 새로운 데이터를 생성.

- **자기회귀 모델 (Autoregressive Model)**: 과거 데이터를 기반으로 미래 값을 예측하는 모델.

## AI의 활용

- **알파폴드**: 단백질의 3차원 구조를 예측하는 딥러닝 모델.

- **자율 주행**: 딥러닝을 활용하여 카메라, 라이다, 레이더 등 센서로부터 입력을 처리하고, 강화 학습 알고리즘을 사용하여 차량 조작 방법을 결정.

- 온디바이스 AI

  : 스마트폰, PC 등 기기 내에서 AI를 실행하는 기술.

  - **전통적인 AI**: 간단한 분류 작업을 수행.
  - **생성형 AI**: 다양한 작업을 수행 가능하며, 거대 언어 모델 (LLM)이 대표적.
  - **NPU (Neural Processing Unit)**: 추론에 최적화된 프로세서.
  - **HBM (High Bandwidth Memory)**: GPU와 RAM 간 초고속 데이터 전송을 위한 메모리 기술.
  - **PIM (Processor in Memory)**: 메모리 자체에서 일부 연산을 수행하는 기술.

## 주요 중요 개념

- LLM (Large Language Model)

  : 대규모 텍스트 데이터를 학습하여 언어 이해와 생성 능력을 갖춘 AI 모델.

  - **어텐션 메커니즘**: AI가 출력 생성 시 입력 텍스트의 특정 부분에 집중할 수 있도록 하는 알고리즘.
  - **트랜스포머**: LLM 연구에 널리 사용되는 신경망 아키텍처.
  - **sLLM (소형 거대언어모델)**: 파라미터 수를 줄여 경량화된 LLM.

- **파운데이션 모델**: 대규모 데이터를 자기 지도학습하여 학습된 후, 사용자의 목적에 맞게 미세 조정되는 기초 모델.

- **파인튜닝 (Fine-tuning)**: 사전 학습된 딥러닝 모델을 특정 작업에 맞게 추가 학습시키는 과정.

- **RAG (Retrieval-Augmented Generation)**: LLM의 한계를 보완하기 위해 외부 데이터 소스를 활용하는 기술.

- **LMM (Large Multimodal Model)**: 텍스트 외 이미지, 음성 등 다양한 유형의 데이터를 결합하여 답변을 제공하는 AI 모델.

## 파인튜닝과 RAG 비교

| 기능              | RAG                                                          | 파인튜닝                                                     |
| ----------------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 지식 업데이트     | **직접 검색**으로 지식을 업데이트하고, 빈번한 재훈련이 불필요하며 동적인 데이터 환경에 적합 | 정적인 데이터를 저장하며, 지식 및 데이터 업데이트를 위해 재훈련이 필요 |
| 외부 지식         | 외부 리소스를 능숙하게 활용하며, 문서나 기타 구조화/비구조화된 데이터베이스에 특히 적합 | 대형 언어 모델과 사전 학습된 외부 지식을 조정하는 데 사용할 수 있지만, 자주 변경되는 데이터 소스에는 덜 실용적일 수 있음 |
| 데이터 처리       | 최소한의 데이터 처리와 핸들링이 필요                         | 고품질 데이터셋에 의존하며, 제한된 데이터 셋은 성능 향상에 도움이 되지 않을 수 있음 |
| 모델 맞춤화       | 정보 검색 및 외부 지식 통합에 중점을 두며, 모델 행동이나 작성 스타일은 완전히 맞춤화하기 어려울 수 있음 | 특정 톤이나 용어 기반의 특정 도메인 지식을 바탕으로 LLM의 행동과 작성 스타일을 조정할 수 있음 |
| 해석 가능성       | 답변은 특정 데이터 소스로 추적 가능하기 때문에, 해석 가능성과 추적성이 더 향상됨 | 블랙박스처럼 작동하여, 모델이 특정 방식으로 반응하는 이유를 항상 명확히 알 수 없으며, 해석 가능성이 상대적으로 낮음 |
| 계산 자원         | 데이터베이스 관련 검색을 지원하기 위해 계산 자원이 필요. 외부 데이터 소스 통합 및 업데이트가 유지되어야 함 | 고품질 훈련 데이터셋의 준비 및 관리, 파인튜닝 목표의 정의, 계산 자원이 필요 |
| 지연 요구 사항    | 데이터 검색이 포함되어 지연이 더 길어질 수 있음              | 파인튜닝 후 LLM은 검색 없이 응답할 수 있어 지연이 더 짧아짐  |
| 할루시네이션 감소 | 검색된 증거에 기반하여 답변을 생성하기 때문에 할루시네이션이 적음 | 모델을 특정 도메인 데이터로 훈련시켜 할루시네이션을 줄일 수 있지만, 익숙하지 않은 입력에 직면했을 때 여전히 할루시네이션을 나타낼 수 있음 |

## 결론

AI 알고리즘은 데이터 기반 학습을 통해 다양한 문제를 해결하고 있으며, 그 발전은 현대 사회에 큰 영향을 미치고 있습니다. **문제 정의, 데이터 수집, 학습, 예측, 평가 및 모니터링**의 단계를 거쳐 작동하며, 머신러닝, 딥러닝, 생성형 AI 등 다양한 분야에서 발전하고 있습니다. 향후 AI 기술은 **온디바이스 AI**를 중심으로 더욱 고도화될 것으로 예상됩니다. 이 기술들이 가져올 혁신적인 변화를 지속적으로 주목해야 할 것입니다.

이 설명문에서는 주어진 소스 내에서 AI 알고리즘의 작동 방식에 대해 상세히 다루었으며, 실제 예시와 함께 AI 알고리즘에 대한 이해를 높이고자 했습니다.
