---
layout: single
title:  "AI 4.머신러닝의 다양한 알고리즘과 성능 평가"
typora-root-url: ../
categories: IT기초
tags: AI
---



## 

### 머신러닝의 정의와 중요성

머신러닝(Machine Learning)은 **데이터 패턴을 스스로 학습하여 예측을 수행하는 알고리즘**으로, 오늘날 인공지능의 핵심 방법론으로 자리 잡았습니다. 기존의 인공지능이 인간이 규칙과 논리를 직접 프로그래밍해야 했던 반면, 머신러닝은 데이터 안에 숨겨진 복잡한 구조나 패턴을 발견하고 이를 스스로 학습하여 새로운 데이터에 대한 예측을 가능하게 합니다. 예를 들어, 사진에서 고양이를 구별하는 인공지능을 만들 때 머신러닝은 다양한 고양이 사진을 학습하여 고양이를 판단하는 방법을 스스로 파악합니다.

머신러닝은 **데이터 수집, 학습 모델 선택, 목적 함수 정의, 파라미터 학습**의 단계를 거쳐 구현됩니다. 먼저, 학습에 필요한 데이터를 수집하고, 수집한 데이터를 가장 잘 표현할 수 있는 학습 모델을 선택합니다. 그다음 모델의 성능을 측정하기 위한 기준인 목적 함수를 설정하고, 마지막으로 파라미터를 조정하며 손실 함수를 최소화하는 방향으로 학습을 진행합니다.

### 머신러닝 알고리즘의 종류와 특징

머신러닝 알고리즘은 학습하려는 문제 유형에 따라 크게 세 가지로 나뉩니다.

- **지도 학습 (Supervised Learning)**: 입력 데이터와 함께 **정답(라벨)**을 학습하는 방식입니다. 모델은 데이터-라벨 쌍을 학습하여 새로운 데이터에 대한 정답을 예측합니다. 예를 들어, 사진 속 인물의 성별을 예측하는 인공지능 개발은 지도 학습의 대표적인 예시입니다.
  - **분류 (Classification)**: 라벨이 이산적으로 주어지는 경우입니다. 예를 들어, 사진 속 강아지의 유무를 판단하거나 손으로 쓴 글씨를 보고 알파벳을 구분하는 문제가 여기에 해당합니다.
  - **회귀 (Regression)**: 라벨이 연속적인 숫자로 주어지는 경우입니다. 집의 평수와 위치 등을 바탕으로 집값을 예측하거나 기상 데이터로부터 다음 날의 기온을 예측하는 문제 등이 회귀에 속합니다.
- **비지도 학습 (Unsupervised Learning)**: **라벨 없이 데이터만으로 학습**하는 방식입니다. 데이터가 나타내는 확률 분포의 특성을 파악하여 학습하는 것이 목표이며, 주로 다음과 같은 방법이 사용됩니다.
  - **군집화 (Clustering)**: 비슷한 특성을 가진 데이터를 그룹으로 묶어 패턴을 파악하는 방법입니다. 반도체 공정에서 불량으로 판정된 웨이퍼 사진을 모아 군집화 알고리즘을 적용하면 불량 원인에 따라 여러 유형으로 분류할 수 있습니다.
  - **차원 축소 (Dimensionality Reduction)**: 고차원 데이터를 저차원으로 축소하여 복잡한 데이터에서 중요한 정보만 남기는 기술입니다. 주성분 분석(PCA)이 대표적인 예시입니다.
  - 생성형 AI 기술도 비지도 학습의 범주에 포함될 수 있습니다. 챗GPT는 '자연어 확률 분포'를 학습하고 이를 통해 주어진 텍스트의 다음 단어를 예측한다고 볼 수 있습니다.
- **강화 학습 (Reinforcement Learning)**: 모델이 주변 환경과 상호작용하며 **최대한 많은 보상을 받도록 학습**하는 방식입니다. 로봇이 장애물을 피하며 목적지까지 이동하는 최적의 경로를 찾는 문제나 자율 주행, 게임 AI 등에 활용됩니다. 최근에는 챗GPT와 같은 대형 언어 모델을 인간의 선호와 일치시키기 위해 인간 피드백을 통한 강화 학습도 주목받고 있습니다.

### 머신러닝의 성능 평가

머신러닝 모델의 궁극적인 목표는 실제 환경에서 처음 보는 데이터에도 우수한 성능을 보이는 것입니다. 모델의 **일반화(Generalization) 능력**이 중요하며, 이를 위해서는 모델의 성능을 정확하게 평가하고 검증하는 과정이 필수입니다.

- **성능 지표 선택**: 문제 유형에 따라 다양한 성능 지표를 사용합니다.

  - 분류 문제

    :

    - **정확도 (Accuracy)**: 전체 예측 중 올바르게 예측한 비율을 나타냅니다. 그러나 데이터셋이 불균형할 경우 정확도만으로는 모델의 성능을 제대로 평가할 수 없습니다.
    - **정밀도 (Precision)**: 모델이 양성으로 예측한 것 중 실제로 양성인 것의 비율입니다.
    - **재현율 (Recall)**: 실제 양성 중 모델이 양성으로 예측한 비율입니다.
    - **F1 스코어 (F1-Score)**: 정밀도와 재현율의 조화 평균으로, 데이터 분류 클래스의 불균형이 심할 때 유용합니다.

  - 회귀 문제

    :

    - **평균 제곱 오차 (MSE)**: 예측값과 실제값의 차이를 제곱한 후 평균을 낸 값입니다.
    - **제곱근 평균 제곱 오차 (RMSE)**: MSE의 제곱근으로, 오차의 크기를 실제 값의 단위와 동일하게 표현합니다.
    - **평균 절대 오차 (MAE)**: 예측값과 실제값 차이의 절댓값을 평균한 값입니다.

- **성능 평가 방법**:

  - **훈련-테스트 분할법 (Train-Test Split)**: 수집된 데이터를 훈련 세트와 테스트 세트로 나누어 모델을 학습하고 성능을 평가하는 가장 간단한 방법입니다. 일반적으로 전체 데이터 중 70~80%를 훈련 세트에 활용합니다.
  - **교차 검증 (Cross Validation)**: 데이터를 K개의 세트로 나누어 K-1개의 세트로 모델을 훈련하고, 나머지 1개 세트로 성능을 평가하는 과정을 K번 반복하여 평균 성능을 구하는 방법입니다.

- **성능 평가 해석**:

  - **과소적합 (Underfitting)**: 모델이 너무 단순해서 데이터의 기본적인 패턴을 학습하지 못하는 경우입니다. 훈련 및 테스트 세트 모두에서 성능이 미달일 경우 과소적합이 발생했다고 볼 수 있습니다.
  - **과대적합 (Overfitting)**: 모델이 너무 복잡해서 기본적인 패턴뿐 아니라 노이즈까지 학습하여 발생합니다. 학습 데이터에서는 높은 성능을 보이지만 테스트 데이터나 새로운 데이터에서는 성능이 떨어집니다.
  - **정규화 (Regularization)**: 과대적합을 방지하기 위해 모델의 복잡도를 제한하거나 페널티를 부과하는 학습 방법입니다.
  - **이중 하강 (Double Descent) 현상**: 모델의 크기가 커질수록 성능이 먼저 저하되다가 일정 크기를 넘어서면 다시 개선되는 현상을 말하며, 딥러닝 분야에서 새롭게 관찰되었습니다.

### 유용한 예시

머신러닝의 다양한 알고리즘과 성능 평가 방법은 다양한 분야에서 활용되고 있습니다.

- 의료 분야

  :

  - **질병 진단**: 지도 학습 알고리즘을 사용하여 환자의 의료 기록, 영상 데이터 등을 분석하여 질병을 진단하고 예측합니다.
  - **신약 개발**: 비지도 학습 알고리즘을 사용하여 새로운 약물 후보를 발굴하거나 기존 약물의 효능을 개선합니다.

- 금융 분야

  :

  - **신용 평가**: 지도 학습 알고리즘을 사용하여 고객의 금융 데이터, 거래 내역 등을 분석하여 신용도를 평가하고 대출 가능성을 예측합니다.
  - **주가 예측**: 강화 학습 알고리즘을 사용하여 주식 시장의 변동을 예측하고 투자 전략을 수립합니다.

- 제조 분야

  :

  - **품질 관리**: 비지도 학습 알고리즘을 사용하여 제품 생산 과정에서 발생하는 불량품을 검출하고 품질을 개선합니다.
  - **공정 최적화**: 강화 학습 알고리즘을 사용하여 생산 공정을 자동화하고 효율성을 높입니다.

- 자율 주행

  :

  - **주변 환경 인식**: 딥러닝을 사용하여 카메라, 라이다, 레이더 등 다양한 센서로부터 입력된 데이터를 처리하고 주변 환경을 인식합니다.
  - **경로 계획 및 제어**: 강화 학습 알고리즘을 사용하여 최적의 주행 경로를 계획하고 차량을 제어합니다.

### 결론

머신러닝은 현대 인공지능 기술의 핵심적인 부분이며, 다양한 알고리즘과 성능 평가 방법을 통해 실제 세계의 여러 문제를 해결하는 데 사용되고 있습니다. 머신러닝을 효과적으로 활용하기 위해서는 각 알고리즘의 특징을 이해하고 문제에 적합한 성능 평가 지표를 선택하는 것이 중요합니다. 또한, 과소적합과 과대적합을 방지하고 모델의 일반화 성능을 향상시키기 위한 다양한 기술과 방법론을 연구하고 적용하는 것이 필요합니다. 특히 최근 딥러닝 분야에서 새롭게 발견된 이중 하강 현상과 같이 기존의 통계학적 개념에 도전하는 현상에 대한 지속적인 연구가 필요합니다.
